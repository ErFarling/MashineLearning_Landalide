# 滑坡易发性评估项目
(一个来自某二本本科生，由于没有专门的老师指导，目前都在自己摸索，并借助deepseek协助进展)
   ## 目标
   使用机器学习与遥感数据分析抚州市滑坡风险区域
   ## 代码文件可直接从 '滑坡3.0.ipynb'开始查看，之前的代码都为试水性尝试。
   数据整合--代码'滑坡3.0.ipynb'(代码排布仍需优化)
   完整模型评估--代码'滑坡3.2.ipynb'

   ## 进展日志
   ### 2025-3-9:第一次将水系.shp文件导入jupyter lab，并实现plot效果图展示
        解决qgis集成anaconda问题
         -代码文件:'滑坡评估.ipynb'

   ### 2025-3-24: 由arcgis完成坐标系同一，历史滑坡数据生成正样本，并排除正样本点随机生成等量数据的负样本，并（依据经纬度）对不同环境因子进行数据整合，整合为一个csv文件
   
   ### 2025-3-29: 导入jupyter lab 进行首次数据预处理尝试，但效果远差于预想，问题百态。f1得分也是完全不及格水平     -代码文件:'滑坡2.0.ipynb'
   
   ### 2025-4-6:  对'滑坡2.0.ipynb' 代码进一步优化，排查所有必须该被删除的特征数据，并依据现有特征创建一些新的特征    -代码文件:'滑坡2.1.ipynb'
   ####    目前状况:使用两种特征选择方法 RFECV 和 SeletFromModel.
            RFECV得到16个特征，交叉验证均值F1只有0.4991
            SelectFromModel在动态阈值搜索后得到更高的F1，但存在警告，说明在某些阈值下没有特征被保留，这可能是因为闻值设置过高。
            不过最终找到了一个合适的國值0.0743,F1提升到0.5873，这说明基于模型的特征重要性可能更有效。
             -代码文件:'滑坡2.1.ipynb'
             
   ####    目前还面临的问题可能：环境因子收集并不足够，比如土壤，归一化植被指数，降雨量

   ### 2025-4-13: 重新对数据收集与整合工作进行优化，相比之前更加系统的知道了哪些数据是需要的。    -代码文件:'滑坡3.0整合.ipynb'
   #### 优化内容： 
           1.新加数据ndvi（归一化植被指数） 
           2.发现arcgis操作有 负样本擦除 遗漏环节
           3.由于arcgis里只做到了将栅格数据多值提取至点到正负样本中，而矢量数据在空间连接时会产生大量空值，无法获得最有效果的数据
             因此改变技术路线：在jupyter里完成了矢量数据的整合与简单优化工作得到一个新的csv文件。   -csv文件:'processed_data.csv'
          -代码文件:'滑坡3.0整合.ipynb'
   #### 下一步，将更好的处理数据（接下来就是缺失值，标准化），接着正式开始模型训练


   ### 2025-4-19：完成了相关性分析 与 模型训练，但分数似乎仍不理想。          -代码文件:'滑坡3.1.ipynb'
   #### 存在问题：热力图处理时存在独热编码的数据，但是其他论文似乎未出现这一问题。是不是岩性数据获取方式存在问题（但是获取到的岩性、土壤数据都是区域性的）


   ### 2025-4-28：对'滑坡3.1.ipynb'代码进一步优化，绘制特征重要性图，并筛选7个特征，使用网格搜索+交叉验证 做模型评估，并绘制混淆矩阵。      -代码文件:'滑坡3.2.ipynb'
   #### 但分数似乎0.74的随机森林就到了上限，最后选用训练好的随机森林对422点评估易发性概率，由于可视化代码操作仍未解决（由于之前数据整合存在流程探索性问题的影响）
   最后保存了滑坡概率的422个含地理几何数据的点（.shp文件）

   
   ## 总结：前面确实走过不少弯路，但是直接的上手去过这个流程是创造效率的重点。（问题：机器学习基础的知识细到每一个代码否还需要继续学习）
   ### 前期的数据整合依然存在大量问题：考虑是否能够 直接导入 所有栅格数据，矢量数据 在代码里完成整个流程（问题：每个文件里有很多数据文件，不知道哪个数据是能用的最主要的）
   例如一个dem文件里有多个.adf文件


   ### 2025-5-2：完成了最后易发性可视化效果图  -代码文件：‘可视化终版.ipynb’，在这个过程中进一步理解了可视化的原理：用400多个点训练模型，再投入整个区域栅格数据，用训练好的模型预测出所有栅格数据点的概率值
   ###           这部分操作原理在现有论文中似乎都并未详细讲解。当然还发现一个很重要的操作步骤，在arcgis里必须提前完成所有数据的投影转换，详细操作：
   投影转换：投影栅格，输出坐标系选择“WGS 1984 UTM Zone 50N”，重采样技术选择“BILINEAR”
重采样：重采样，输出像元大小选择与基准图层相同（基准文件不用选），重采样技术选择“BILINEAR”，最下面点击“环境…”设置环境参数，点开“处理范围”，范围只要选择与基准文件相同就可以了（如果栅格数据太大选择输入的并集的话数据量会非常非常大，处理时间会非常非常长），捕捉栅格选择基准文件图层。基准文件没有设置像元大小就要往下滑，点开“栅格分析”，像元大小选择“如下面指定”，把数字改成“30”，其他的数据就不用设置这个了。
裁剪到宜黄县：按掩膜提取，如果几个数据都做好了就可以右击选择批处理，把几个图层都拖进对话框，“输入栅格数据或要素掩膜数据”选择“宜黄县”shp文件
   #### 最后所有环境因子统一成栅格数据，进行整合，（环境因子排序要与训练时一致）   -代码文件：‘整合3.0终版’ 
   
   ## 总结，目前最好的方案是在arcgis里统一整个环境因子为栅格，统一投影/裁剪，来获取可直接供模型训练的数据。
